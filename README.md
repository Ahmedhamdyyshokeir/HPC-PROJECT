# HPC-PROJECT
A complete distributed computing project that uses both traditional high-performance computing and modern big data methods to apply machine learning on bioinformatics datasets.


#Project Overview
Task1: The project explores two complementary distributed-computing strategies:

Task2: Conventional mini-HPC cluster with MPI – used to parallelize machine-learning workloads.

Hybrid HPC + Big-Data setup with Docker Swarm & Apache Spark – combining container orchestration and Spark’s distributed engine.

Both architectures are benchmarked on a real bioinformatics task: classifying leukemia subtypes from the Golub gene-expression dataset.
